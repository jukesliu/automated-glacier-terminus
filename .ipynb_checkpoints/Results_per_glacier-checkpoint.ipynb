{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot terminus picks over images and terminus position time series\n",
    "\n",
    "#### Jukes Liu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# # !{sys.executable} -m pip install fiona\n",
    "# !{sys.executable} -m pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import pandas as pd    \n",
    "from time import sleep\n",
    "from IPython.display import clear_output\n",
    "import scipy.stats\n",
    "import datetime\n",
    "import math\n",
    "import shutil\n",
    "import subprocess\n",
    "\n",
    "csvpaths = '/home/jukes/Documents/Sample_glaciers/'\n",
    "basepath = '/media/jukes/jukes1/LS8aws/'\n",
    "massorsize = \"mass\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data from csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Read in __image dates__ from imgdates.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2597, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scene</th>\n",
       "      <th>datetimes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3223</th>\n",
       "      <td>LC08_L1TP_010002_20130327_20170505_01_T1</td>\n",
       "      <td>2013-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>LC08_L1TP_015001_20130402_20170310_01_T1</td>\n",
       "      <td>2013-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3147</th>\n",
       "      <td>LC08_L1TP_006003_20130403_20170505_01_T1</td>\n",
       "      <td>2013-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3368</th>\n",
       "      <td>LC08_L1TP_012002_20130404_20170310_01_T1</td>\n",
       "      <td>2013-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>LC08_L1TP_034005_20130405_20170310_01_T1</td>\n",
       "      <td>2013-04-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Scene   datetimes\n",
       "3223  LC08_L1TP_010002_20130327_20170505_01_T1  2013-03-27\n",
       "3597  LC08_L1TP_015001_20130402_20170310_01_T1  2013-04-02\n",
       "3147  LC08_L1TP_006003_20130403_20170505_01_T1  2013-04-03\n",
       "3368  LC08_L1TP_012002_20130404_20170310_01_T1  2013-04-04\n",
       "264   LC08_L1TP_034005_20130405_20170310_01_T1  2013-04-05"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in datetags csv as datetime_df\n",
    "datetime_df = pd.read_csv(csvpaths+'imgdates_sample10.csv', sep=',', dtype=str, header=0, names=['Scene', 'datetimes'])\n",
    "print(datetime_df.shape)\n",
    "datetime_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Read in csv with the __metric and order__ for each terminus pick from terminuspicks_massorsize_date.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis_date = '2020_05_07'\n",
    "# for file in os.listdir(csvpaths):\n",
    "#     if analysis_date in file and file.endswith('.csv'):\n",
    "#         thefile = file\n",
    "# order_df = pd.read_csv(csvpaths+thefile, sep=',', dtype=str, header=1, usecols=[0,1,2,3,4])\n",
    "# order_df = order_df.dropna()\n",
    "# print(order_df.shape)\n",
    "# order_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Read in __centerline information__ for each terminus box rom Boxes_coords_pathrows.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lmid50_x</th>\n",
       "      <th>lmid50_y</th>\n",
       "      <th>rmid50_x</th>\n",
       "      <th>m50</th>\n",
       "      <th>b50</th>\n",
       "      <th>lmid25_x</th>\n",
       "      <th>lmid25_y</th>\n",
       "      <th>rmid25_x</th>\n",
       "      <th>m25</th>\n",
       "      <th>b25</th>\n",
       "      <th>lmid75_x</th>\n",
       "      <th>lmid75_y</th>\n",
       "      <th>rmid75_x</th>\n",
       "      <th>m75</th>\n",
       "      <th>b75</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BoxID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>68.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.20567375886524822</td>\n",
       "      <td>84.91134751773049</td>\n",
       "      <td>71.75</td>\n",
       "      <td>84.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.20284697508896798</td>\n",
       "      <td>69.24290780141844</td>\n",
       "      <td>65.25</td>\n",
       "      <td>114.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.20848056537102475</td>\n",
       "      <td>100.57978723404256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>148.5</td>\n",
       "      <td>222.5</td>\n",
       "      <td>285.5</td>\n",
       "      <td>-0.1386861313868613</td>\n",
       "      <td>243.09489051094891</td>\n",
       "      <td>144.75</td>\n",
       "      <td>194.75</td>\n",
       "      <td>281.25</td>\n",
       "      <td>-0.14285714285714285</td>\n",
       "      <td>214.82481751824818</td>\n",
       "      <td>152.25</td>\n",
       "      <td>250.25</td>\n",
       "      <td>289.75</td>\n",
       "      <td>-0.13454545454545455</td>\n",
       "      <td>271.3649635036496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>141.5</td>\n",
       "      <td>390.5</td>\n",
       "      <td>410.5</td>\n",
       "      <td>-0.6933085501858736</td>\n",
       "      <td>488.60315985130114</td>\n",
       "      <td>129.25</td>\n",
       "      <td>372.75</td>\n",
       "      <td>398.25</td>\n",
       "      <td>-0.6923791821561338</td>\n",
       "      <td>462.36013011152414</td>\n",
       "      <td>153.75</td>\n",
       "      <td>408.25</td>\n",
       "      <td>422.75</td>\n",
       "      <td>-0.6942379182156134</td>\n",
       "      <td>514.8461895910781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002</th>\n",
       "      <td>406.5</td>\n",
       "      <td>524.5</td>\n",
       "      <td>689.0</td>\n",
       "      <td>-0.08672566371681416</td>\n",
       "      <td>559.7539823008849</td>\n",
       "      <td>403.25</td>\n",
       "      <td>486.25</td>\n",
       "      <td>686.0</td>\n",
       "      <td>-0.08576480990274093</td>\n",
       "      <td>521.2221238938054</td>\n",
       "      <td>409.75</td>\n",
       "      <td>562.75</td>\n",
       "      <td>692.0</td>\n",
       "      <td>-0.08768821966341896</td>\n",
       "      <td>598.2858407079646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001</th>\n",
       "      <td>101.0</td>\n",
       "      <td>142.0</td>\n",
       "      <td>174.5</td>\n",
       "      <td>0.08163265306122448</td>\n",
       "      <td>133.75510204081633</td>\n",
       "      <td>102.0</td>\n",
       "      <td>132.5</td>\n",
       "      <td>174.75</td>\n",
       "      <td>0.07560137457044673</td>\n",
       "      <td>124.1734693877551</td>\n",
       "      <td>100.0</td>\n",
       "      <td>151.5</td>\n",
       "      <td>174.25</td>\n",
       "      <td>0.08754208754208755</td>\n",
       "      <td>143.33673469387756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      lmid50_x lmid50_y rmid50_x                   m50                 b50  \\\n",
       "BoxID                                                                        \n",
       "120       68.5     99.0    139.0   0.20567375886524822   84.91134751773049   \n",
       "174      148.5    222.5    285.5   -0.1386861313868613  243.09489051094891   \n",
       "259      141.5    390.5    410.5   -0.6933085501858736  488.60315985130114   \n",
       "002      406.5    524.5    689.0  -0.08672566371681416   559.7539823008849   \n",
       "001      101.0    142.0    174.5   0.08163265306122448  133.75510204081633   \n",
       "\n",
       "      lmid25_x lmid25_y rmid25_x                   m25                 b25  \\\n",
       "BoxID                                                                        \n",
       "120      71.75     84.0    142.0   0.20284697508896798   69.24290780141844   \n",
       "174     144.75   194.75   281.25  -0.14285714285714285  214.82481751824818   \n",
       "259     129.25   372.75   398.25   -0.6923791821561338  462.36013011152414   \n",
       "002     403.25   486.25    686.0  -0.08576480990274093   521.2221238938054   \n",
       "001      102.0    132.5   174.75   0.07560137457044673   124.1734693877551   \n",
       "\n",
       "      lmid75_x lmid75_y rmid75_x                   m75                 b75  \n",
       "BoxID                                                                       \n",
       "120      65.25    114.0    136.0   0.20848056537102475  100.57978723404256  \n",
       "174     152.25   250.25   289.75  -0.13454545454545455   271.3649635036496  \n",
       "259     153.75   408.25   422.75   -0.6942379182156134   514.8461895910781  \n",
       "002     409.75   562.75    692.0  -0.08768821966341896   598.2858407079646  \n",
       "001      100.0    151.5   174.25   0.08754208754208755  143.33673469387756  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centerline_df = pd.read_csv(csvpaths+'Boxes_coords_pathrows_sample5.csv', sep=',', dtype=str, header=0)\n",
    "centerline_df = centerline_df.set_index('BoxID')\n",
    "print(centerline_df.shape)\n",
    "centerline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Read in __glacier velocities__ from Glacier_velocities.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in glacier velocity data\n",
    "flowspeed_df= pd.read_csv(csvpaths+'Glacier_vel_measures_sample10.csv', sep=',', dtype=str)\n",
    "flowspeed_df = flowspeed_df.set_index('BoxID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import functions:\n",
    "\n",
    "There are 5 functions that are used throughout the script. __calc_changerates()__ takes a dataframe containing terminus positions and dates of analysis and calculates the terminus change rates. __remove_dips()__ takes a dataframe and a flow speed threshold and removes all points that show an unrealistically large negative change rate followed by an unrealistically large positive change rate. __remove_jumps()__ takes the same inputs and removes all values that show an unrealistically large positive change rate (a jump). __within()__ takes a test value and determines whether it is within a given interval around the set value. This is used for determining whether the points of the centerline \"intersect\" with the terminus pick points. __distance()__ calculates distance between 2 points using the distance formula. This will be used to calculate terminus position (distance between interesction point and reference point)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/jukes/automated-glacier-terminus')\n",
    "\n",
    "from automated_terminus_functions import calc_changerates1, remove_dips, remove_jumps, within, distance, to_datetimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Plot analyzed images and terminus picks for one glacier sequentially"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If images have not been converted to png from pgm, run the following cell but change the BoxID to the right ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoxIDs= set(list(order_df['BoxID']))\n",
    "# for BoxID in BoxIDs:\n",
    "#     command = 'cd '+basepath+'Box'+str(BoxID)+'/rotated/; '+'mogrify -format png *.TIF'\n",
    "#     print(command)\n",
    "#     subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in the images, scene names, and dat file names for all the resulting terminus picks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box120\n",
      "Results folder wiped and new created\n"
     ]
    }
   ],
   "source": [
    "BOI= '120'; print(\"Box\"+BOI)\n",
    "\n",
    "metric = \"Datfiles_c1/\"; imagepath = basepath+\"Box\"+BOI+\"/rotated_c1/\"\n",
    "\n",
    "#grab the order_df subset for just the box:\n",
    "order_box_df = pd.read_csv(csvpaths+'Tpos_Box'+BOI+'_flowline50_filtered.csv',  dtype=str, usecols=[1,2,3,4,5,6,7,8,9])\n",
    "\n",
    "#make results directory in BoxID folder if it doesn't already exist\n",
    "if os.path.exists(basepath+\"Box\"+BOI+\"/Results_c1/\"):\n",
    "    shutil.rmtree(basepath+\"Box\"+BOI+\"/Results_c1/\"); print(\"Results folder wiped and new created\")\n",
    "    os.mkdir(basepath+\"Box\"+BOI+\"/Results_c1/\")\n",
    "#OTHERWISE, create the folder and download into it\n",
    "else:\n",
    "    os.mkdir(basepath+\"Box\"+BOI+\"/Results_c1/\"); print(\"Results folder made\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scene</th>\n",
       "      <th>Scale</th>\n",
       "      <th>datetimes</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Order</th>\n",
       "      <th>tpos</th>\n",
       "      <th>X</th>\n",
       "      <th>changerate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LC08_L1TP_233017_20130530_20170504_01_T1</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>372536.4257812500</td>\n",
       "      <td>1</td>\n",
       "      <td>562.5</td>\n",
       "      <td>[106.0, 107.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LC08_L1TP_233017_20130818_20180426_01_T1</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-08-18</td>\n",
       "      <td>202961.7529296875</td>\n",
       "      <td>1</td>\n",
       "      <td>562.5</td>\n",
       "      <td>[106.0, 107.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LC08_L1TP_233017_20130903_20170502_01_T1</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>195023.0095214844</td>\n",
       "      <td>1</td>\n",
       "      <td>562.5</td>\n",
       "      <td>[106.0, 106.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LC08_L1TP_232018_20130912_20170502_01_T1</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-09-12</td>\n",
       "      <td>221347.8078613281</td>\n",
       "      <td>1</td>\n",
       "      <td>562.5</td>\n",
       "      <td>[106.0, 107.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LC08_L1TP_232017_20130928_20180528_01_T1</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-09-28</td>\n",
       "      <td>437645.7824707031</td>\n",
       "      <td>1</td>\n",
       "      <td>562.5</td>\n",
       "      <td>[106.0, 107.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Scene Scale   datetimes  \\\n",
       "1  LC08_L1TP_233017_20130530_20170504_01_T1   000  2013-05-30   \n",
       "2  LC08_L1TP_233017_20130818_20180426_01_T1   000  2013-08-18   \n",
       "3  LC08_L1TP_233017_20130903_20170502_01_T1   000  2013-09-03   \n",
       "4  LC08_L1TP_232018_20130912_20170502_01_T1   000  2013-09-12   \n",
       "5  LC08_L1TP_232017_20130928_20180528_01_T1   000  2013-09-28   \n",
       "\n",
       "              Metric Order   tpos               X changerate  \n",
       "1  372536.4257812500     1  562.5  [106.0, 107.0]        0.0  \n",
       "2  202961.7529296875     1  562.5  [106.0, 107.0]        0.0  \n",
       "3  195023.0095214844     1  562.5  [106.0, 106.0]        0.0  \n",
       "4  221347.8078613281     1  562.5  [106.0, 107.0]        0.0  \n",
       "5  437645.7824707031     1  562.5  [106.0, 107.0]        0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_box_df = order_box_df.drop('BoxID', axis=1)\n",
    "order_box_df = order_box_df.dropna()\n",
    "print(order_box_df.shape)\n",
    "order_box_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1115 1115 1115 1115 1115 1115\n",
      "(1115, 6)\n"
     ]
    }
   ],
   "source": [
    "#make lists to store image data and grab image files\n",
    "image_arrays = []; dats = []; trimdats = []; imgnames = []; boxids = []; scales = []\n",
    "\n",
    "#image path\n",
    "imgfiles = os.listdir(imagepath)\n",
    "\n",
    "for imgfile in imgfiles:\n",
    "    #grab image files and append to images list\n",
    "    if imgfile.endswith(BOI+\"_PS.png\"):\n",
    "#         print(imgfile)\n",
    "        image = mpimg.imread(imagepath+imgfile); imgname = imgfile[0:-4]; scenename = imgname[2:42]\n",
    "        \n",
    "        pathtodat = imagepath+imgname+\".pgm_max_gaussian/\"+metric\n",
    "        datfiles = os.listdir(pathtodat)\n",
    "        \n",
    "        #if there are datfiles, grab the trimmed and non-trimmed files\n",
    "        if len(datfiles) > 1: \n",
    "            #find the trimmed dat file and the original\n",
    "            for dat in datfiles:\n",
    "                if \"trim\" in dat:\n",
    "                    datfile_trim = dat\n",
    "                    #append to trimmed dats list\n",
    "                    trimdats.append(datfile_trim)\n",
    "                    #grab the scale and append the equivalent original dat\n",
    "                    scale = dat[-7:-4]\n",
    "                    datfile = \"terminus_\"+scale+\".dat\"\n",
    "                    dats.append(datfile)\n",
    "                    \n",
    "                    #append the image array and the image name to the list\n",
    "                    image_arrays.append(image); imgnames.append(scenename); boxids.append(BOI); scales.append(scale)\n",
    "\n",
    "print(len(image_arrays), len(dats), len(trimdats), len(imgnames),len(boxids), len(scales))\n",
    "images_df = pd.DataFrame(list(zip(imgnames, boxids, image_arrays, dats, trimdats, scales)),\n",
    "              columns=['Scene','BoxID','Image_array', 'Dat_filename', \"Trimmed_dat_filename\", \"Scale\"])\n",
    "print(images_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scene</th>\n",
       "      <th>BoxID</th>\n",
       "      <th>Image_array</th>\n",
       "      <th>Dat_filename</th>\n",
       "      <th>Trimmed_dat_filename</th>\n",
       "      <th>Scale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LC08_L1TP_232017_20190913_20190913_01_RT</td>\n",
       "      <td>120</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...</td>\n",
       "      <td>terminus_002.dat</td>\n",
       "      <td>terminus_trim_002.dat</td>\n",
       "      <td>002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LC08_L1TP_232017_20190913_20190913_01_RT</td>\n",
       "      <td>120</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...</td>\n",
       "      <td>terminus_001.dat</td>\n",
       "      <td>terminus_trim_001.dat</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LC08_L1TP_232017_20190913_20190913_01_RT</td>\n",
       "      <td>120</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...</td>\n",
       "      <td>terminus_003.dat</td>\n",
       "      <td>terminus_trim_003.dat</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LC08_L1TP_232017_20190913_20190913_01_RT</td>\n",
       "      <td>120</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...</td>\n",
       "      <td>terminus_000.dat</td>\n",
       "      <td>terminus_trim_000.dat</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LC08_L1TP_232017_20190913_20190913_01_RT</td>\n",
       "      <td>120</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...</td>\n",
       "      <td>terminus_004.dat</td>\n",
       "      <td>terminus_trim_004.dat</td>\n",
       "      <td>004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>LC08_L1GT_232018_20200119_20200119_01_RT</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_002.dat</td>\n",
       "      <td>terminus_trim_002.dat</td>\n",
       "      <td>002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>LC08_L1GT_232018_20200119_20200119_01_RT</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_001.dat</td>\n",
       "      <td>terminus_trim_001.dat</td>\n",
       "      <td>001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>LC08_L1GT_232018_20200119_20200119_01_RT</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_003.dat</td>\n",
       "      <td>terminus_trim_003.dat</td>\n",
       "      <td>003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1113</th>\n",
       "      <td>LC08_L1GT_232018_20200119_20200119_01_RT</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_000.dat</td>\n",
       "      <td>terminus_trim_000.dat</td>\n",
       "      <td>000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>LC08_L1GT_232018_20200119_20200119_01_RT</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_004.dat</td>\n",
       "      <td>terminus_trim_004.dat</td>\n",
       "      <td>004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1115 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Scene BoxID  \\\n",
       "0     LC08_L1TP_232017_20190913_20190913_01_RT   120   \n",
       "1     LC08_L1TP_232017_20190913_20190913_01_RT   120   \n",
       "2     LC08_L1TP_232017_20190913_20190913_01_RT   120   \n",
       "3     LC08_L1TP_232017_20190913_20190913_01_RT   120   \n",
       "4     LC08_L1TP_232017_20190913_20190913_01_RT   120   \n",
       "...                                        ...   ...   \n",
       "1110  LC08_L1GT_232018_20200119_20200119_01_RT   120   \n",
       "1111  LC08_L1GT_232018_20200119_20200119_01_RT   120   \n",
       "1112  LC08_L1GT_232018_20200119_20200119_01_RT   120   \n",
       "1113  LC08_L1GT_232018_20200119_20200119_01_RT   120   \n",
       "1114  LC08_L1GT_232018_20200119_20200119_01_RT   120   \n",
       "\n",
       "                                            Image_array      Dat_filename  \\\n",
       "0     [[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...  terminus_002.dat   \n",
       "1     [[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...  terminus_001.dat   \n",
       "2     [[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...  terminus_003.dat   \n",
       "3     [[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...  terminus_000.dat   \n",
       "4     [[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...  terminus_004.dat   \n",
       "...                                                 ...               ...   \n",
       "1110  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_002.dat   \n",
       "1111  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_001.dat   \n",
       "1112  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_003.dat   \n",
       "1113  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_000.dat   \n",
       "1114  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_004.dat   \n",
       "\n",
       "       Trimmed_dat_filename Scale  \n",
       "0     terminus_trim_002.dat   002  \n",
       "1     terminus_trim_001.dat   001  \n",
       "2     terminus_trim_003.dat   003  \n",
       "3     terminus_trim_000.dat   000  \n",
       "4     terminus_trim_004.dat   004  \n",
       "...                     ...   ...  \n",
       "1110  terminus_trim_002.dat   002  \n",
       "1111  terminus_trim_001.dat   001  \n",
       "1112  terminus_trim_003.dat   003  \n",
       "1113  terminus_trim_000.dat   000  \n",
       "1114  terminus_trim_004.dat   004  \n",
       "\n",
       "[1115 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join dates to images_df by joining on Scene:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2597, 2)\n",
      "(1115, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scene</th>\n",
       "      <th>BoxID</th>\n",
       "      <th>Image_array</th>\n",
       "      <th>Dat_filename</th>\n",
       "      <th>Trimmed_dat_filename</th>\n",
       "      <th>Scale</th>\n",
       "      <th>datetimes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LC08_L1TP_233017_20130412_20170505_01_T1</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_002.dat</td>\n",
       "      <td>terminus_trim_002.dat</td>\n",
       "      <td>002</td>\n",
       "      <td>2013-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LC08_L1TP_233017_20130412_20170505_01_T1</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_001.dat</td>\n",
       "      <td>terminus_trim_001.dat</td>\n",
       "      <td>001</td>\n",
       "      <td>2013-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LC08_L1TP_233017_20130412_20170505_01_T1</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_003.dat</td>\n",
       "      <td>terminus_trim_003.dat</td>\n",
       "      <td>003</td>\n",
       "      <td>2013-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LC08_L1TP_233017_20130412_20170505_01_T1</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_000.dat</td>\n",
       "      <td>terminus_trim_000.dat</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-04-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LC08_L1TP_233017_20130412_20170505_01_T1</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_004.dat</td>\n",
       "      <td>terminus_trim_004.dat</td>\n",
       "      <td>004</td>\n",
       "      <td>2013-04-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Scene BoxID  \\\n",
       "5  LC08_L1TP_233017_20130412_20170505_01_T1   120   \n",
       "6  LC08_L1TP_233017_20130412_20170505_01_T1   120   \n",
       "7  LC08_L1TP_233017_20130412_20170505_01_T1   120   \n",
       "8  LC08_L1TP_233017_20130412_20170505_01_T1   120   \n",
       "9  LC08_L1TP_233017_20130412_20170505_01_T1   120   \n",
       "\n",
       "                                         Image_array      Dat_filename  \\\n",
       "5  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_002.dat   \n",
       "6  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_001.dat   \n",
       "7  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_003.dat   \n",
       "8  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_000.dat   \n",
       "9  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_004.dat   \n",
       "\n",
       "    Trimmed_dat_filename Scale   datetimes  \n",
       "5  terminus_trim_002.dat   002  2013-04-12  \n",
       "6  terminus_trim_001.dat   001  2013-04-12  \n",
       "7  terminus_trim_003.dat   003  2013-04-12  \n",
       "8  terminus_trim_000.dat   000  2013-04-12  \n",
       "9  terminus_trim_004.dat   004  2013-04-12  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_df.sort_values(by='Scene')\n",
    "datetime_df = datetime_df.sort_values(by='Scene')\n",
    "print(datetime_df.shape)\n",
    "new_df = images_df.merge(datetime_df, how= 'inner', on = 'Scene')\n",
    "dated_images_df = new_df.sort_values(by='datetimes', ascending = True)\n",
    "print(dated_images_df.shape)\n",
    "dated_images_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Join \"order\" to dated_images_df by joining on scale and scene and sort the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scene</th>\n",
       "      <th>BoxID</th>\n",
       "      <th>Image_array</th>\n",
       "      <th>Dat_filename</th>\n",
       "      <th>Trimmed_dat_filename</th>\n",
       "      <th>Scale</th>\n",
       "      <th>datetimes</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Order</th>\n",
       "      <th>tpos</th>\n",
       "      <th>X</th>\n",
       "      <th>changerate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LC08_L1TP_233017_20130530_20170504_01_T1</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_000.dat</td>\n",
       "      <td>terminus_trim_000.dat</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>372536.4257812500</td>\n",
       "      <td>1</td>\n",
       "      <td>562.5</td>\n",
       "      <td>[106.0, 107.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LC08_L1TP_233017_20130818_20180426_01_T1</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_000.dat</td>\n",
       "      <td>terminus_trim_000.dat</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-08-18</td>\n",
       "      <td>202961.7529296875</td>\n",
       "      <td>1</td>\n",
       "      <td>562.5</td>\n",
       "      <td>[106.0, 107.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LC08_L1TP_233017_20130903_20170502_01_T1</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_000.dat</td>\n",
       "      <td>terminus_trim_000.dat</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-09-03</td>\n",
       "      <td>195023.0095214844</td>\n",
       "      <td>1</td>\n",
       "      <td>562.5</td>\n",
       "      <td>[106.0, 106.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LC08_L1TP_232018_20130912_20170502_01_T1</td>\n",
       "      <td>120</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>terminus_000.dat</td>\n",
       "      <td>terminus_trim_000.dat</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-09-12</td>\n",
       "      <td>221347.8078613281</td>\n",
       "      <td>1</td>\n",
       "      <td>562.5</td>\n",
       "      <td>[106.0, 107.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LC08_L1TP_232017_20130928_20180528_01_T1</td>\n",
       "      <td>120</td>\n",
       "      <td>[[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...</td>\n",
       "      <td>terminus_000.dat</td>\n",
       "      <td>terminus_trim_000.dat</td>\n",
       "      <td>000</td>\n",
       "      <td>2013-09-28</td>\n",
       "      <td>437645.7824707031</td>\n",
       "      <td>1</td>\n",
       "      <td>562.5</td>\n",
       "      <td>[106.0, 107.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Scene BoxID  \\\n",
       "0  LC08_L1TP_233017_20130530_20170504_01_T1   120   \n",
       "1  LC08_L1TP_233017_20130818_20180426_01_T1   120   \n",
       "2  LC08_L1TP_233017_20130903_20170502_01_T1   120   \n",
       "3  LC08_L1TP_232018_20130912_20170502_01_T1   120   \n",
       "4  LC08_L1TP_232017_20130928_20180528_01_T1   120   \n",
       "\n",
       "                                         Image_array      Dat_filename  \\\n",
       "0  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_000.dat   \n",
       "1  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_000.dat   \n",
       "2  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_000.dat   \n",
       "3  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  terminus_000.dat   \n",
       "4  [[[0.0, 0.0, 0.0, 1.0], [0.0, 0.0, 0.0, 1.0], ...  terminus_000.dat   \n",
       "\n",
       "    Trimmed_dat_filename Scale   datetimes             Metric Order   tpos  \\\n",
       "0  terminus_trim_000.dat   000  2013-05-30  372536.4257812500     1  562.5   \n",
       "1  terminus_trim_000.dat   000  2013-08-18  202961.7529296875     1  562.5   \n",
       "2  terminus_trim_000.dat   000  2013-09-03  195023.0095214844     1  562.5   \n",
       "3  terminus_trim_000.dat   000  2013-09-12  221347.8078613281     1  562.5   \n",
       "4  terminus_trim_000.dat   000  2013-09-28  437645.7824707031     1  562.5   \n",
       "\n",
       "                X changerate  \n",
       "0  [106.0, 107.0]        0.0  \n",
       "1  [106.0, 107.0]        0.0  \n",
       "2  [106.0, 106.0]        0.0  \n",
       "3  [106.0, 107.0]        0.0  \n",
       "4  [106.0, 107.0]        0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_images_df = dated_images_df.merge(order_box_df, how='inner', on=['Scene', 'Scale', 'datetimes'])\n",
    "#sort the DataFrame by date of delineation from earliest to latest AND order\n",
    "final_images_df = final_images_df.sort_values(by=['datetimes','Scene','Order'], ascending=True)\n",
    "final_images_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #separate the df out into data for the different centrlines\n",
    "# final_images_25 = final_images_df.copy()\n",
    "# final_images_75 = final_images_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_images_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate terminus positions:\n",
    "\n",
    "### Terminus position:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(211, 18)\n"
     ]
    }
   ],
   "source": [
    "#LOAD IN REFERENCE POINTS to calculate terminus position with respect to\n",
    "box_midpoint_x = np.float(centerline_df.loc[BOI, 'lmid50_x']); box_midpoint_y = np.float(centerline_df.loc[BOI, 'lmid50_y'])\n",
    "boxmid_x_25 = np.float(centerline_df.loc[BOI, 'lmid25_x']); boxmid_y_25 = np.float(centerline_df.loc[BOI, 'lmid25_y'])\n",
    "boxmid_x_75 = np.float(centerline_df.loc[BOI, 'lmid75_x']); boxmid_y_75 = np.float(centerline_df.loc[BOI, 'lmid75_y'])\n",
    "\n",
    "#GRAB CENTERLINE POINTS\n",
    "#grab slopes and intercepts from the dataframe\n",
    "c_slope = float(centerline_df.loc[BOI]['m50']); c_intercept = float(centerline_df.loc[BOI]['b50']) \n",
    "c25_slope = float(centerline_df.loc[BOI]['m25']); c25_intercept = float(centerline_df.loc[BOI]['b25'])\n",
    "c75_slope = float(centerline_df.loc[BOI]['m75']); c75_intercept = float(centerline_df.loc[BOI]['b75'])  \n",
    "\n",
    "#grab range of x-values\n",
    "xmin50 = float(box_midpoint_x); xmax50 = float(centerline_df.loc[BOI, 'rmid50_x']); ymid50 = float(box_midpoint_y)\n",
    "xmin25 = float(boxmid_x_25); xmax25 = float(centerline_df.loc[BOI, 'rmid25_x']); ymid25 = float(boxmid_y_25)\n",
    "xmin75 = float(boxmid_x_75); xmax75 = float(centerline_df.loc[BOI, 'lmid75_x']); ymid75 = float(boxmid_y_75)\n",
    "xmax = np.max([xmax50, xmax25, xmax75]); xmin = np.min([xmin50, xmin25, xmin75]); c_x = np.linspace(xmin, xmax, int(xmax-xmin)*2)\n",
    "\n",
    "#calculate y-values using the various centerlines\n",
    "c_y = c_slope*c_x + c_intercept; c_y_25 = c25_slope*c_x + c25_intercept; c_y_75 = c75_slope*c_x + c75_intercept\n",
    "\n",
    "#LISTS TO HOLD TERMINUS POSITIONS AND INTERSECTION POINTS\n",
    "terminus_positions = []; tpositions_25 = []; tpositions_75 = []\n",
    "intersections = []; X25 = []; X75 = []\n",
    "\n",
    "#for each scene and scale:\n",
    "for index, row in final_images_df.iterrows():\n",
    "    trimdat = row['Trimmed_dat_filename']; dat = row['Dat_filename']; scene = row['Scene']    \n",
    "    #CALCULATE TERMINUS POSITION\n",
    "    #load in dat files and calculate intersection points\n",
    "    datpath = imagepath+\"R_\"+scene+\"_B8_Buffer\"+BOI+\"_PS.pgm_max_gaussian/\"+metric\n",
    "#     term_trimdat = np.loadtxt(datpath+trimdat)\n",
    "    term_dat = np.loadtxt(datpath+dat)                          \n",
    "    intersect_xs = []; intersect_xs_25 = []; intersect_xs_75 = []\n",
    "    intersect_ys = []; intersect_ys_25 = []; intersect_ys_75 = []\n",
    "    \n",
    "    #loop through all the x,y values for the centerline\n",
    "    for j in range(0, len(c_x)):\n",
    "        x = c_x[j]; y = c_y[j]; y25 = c_y_25[j]; y75 = c_y_75[j]        \n",
    "        interval = 0.6\n",
    "        #where are the intersections with the terminus pick?\n",
    "#         for dat_x, dat_y in term_trimdat:\n",
    "        for dat_x, dat_y in term_dat:\n",
    "            #midway centerline\n",
    "            if within(dat_x, x, interval) and within (dat_y, y, interval):\n",
    "                #intersect_x = dat_x; intersect_y = dat_y; intersect_found = True\n",
    "                intersect_xs.append(dat_x); intersect_ys.append(dat_y)            \n",
    "            #1/4th centerline\n",
    "            if within(dat_x, x, interval) and within (dat_y, y25, interval):\n",
    "                intersect_xs_25.append(dat_x); intersect_ys_25.append(dat_y)              \n",
    "            #3/4th centerline\n",
    "            if within(dat_x, x, interval) and within (dat_y, y75, interval):\n",
    "                intersect_xs_75.append(dat_x); intersect_ys_75.append(dat_y)\n",
    "    #for 50 centerline\n",
    "    #if no intersections are found with the terminus line, append Nans\n",
    "    if len(intersect_xs) == 0:\n",
    "        tpos50 = np.NaN; intersect_x = np.NaN; intersect_y = np.NaN\n",
    "    #if at least one is found:\n",
    "    else:\n",
    "        #intersection with the greatest x\n",
    "        #use distance formula to calculate distance between\n",
    "        max_index = intersect_xs.index(np.max(intersect_xs))\n",
    "        intersect_x = intersect_xs[max_index]; intersect_y = intersect_ys[max_index]\n",
    "#         term_position = distance(xmin50, ymid50, intersect_x, intersect_y)*15.0\n",
    "        tpos50 = (intersect_x-xmin50)*15.0\n",
    "#         print(tpos50)\n",
    "\n",
    "    #for 25 centerline\n",
    "    if len(intersect_xs_25) == 0:\n",
    "        tpos25 = np.NaN; intersect_x25 = np.NaN; intersect_y25 = np.NaN\n",
    "    else:\n",
    "        max_index_25 = intersect_xs_25.index(np.max(intersect_xs_25))\n",
    "        intersect_x25 = intersect_xs_25[max_index_25]; intersect_y25 = intersect_ys_25[max_index_25]\n",
    "        tpos25 = (intersect_x25-xmin25)*15.0\n",
    "#         tpos25 = distance(xmin25, ymid25, intersect_x25, intersect_y25)*15.0\n",
    "    \n",
    "    #for 75 centerline\n",
    "    if len(intersect_xs_75) == 0:\n",
    "        tpos75 = np.NaN; intersect_x75 = np.NaN; intersect_y75 = np.NaN\n",
    "    else:\n",
    "        max_index_75 = intersect_xs_75.index(np.max(intersect_xs_75))\n",
    "        intersect_x75 = intersect_xs_75[max_index_75]; intersect_y75 = intersect_ys_75[max_index_75]\n",
    "        tpos75 = (intersect_x75-xmin75)*15.0\n",
    "#         tpos75 = distance(xmin75, ymid75, intersect_x75, intersect_y75)*15.0\n",
    "        \n",
    "    #append to lists\n",
    "    terminus_positions.append(tpos50); tpositions_25.append(tpos25); tpositions_75.append(tpos75)\n",
    "    intersections.append([intersect_x, intersect_y]); X25.append([intersect_x25, intersect_y25]); X75.append([intersect_x75, intersect_y75])\n",
    "    \n",
    "# ADD TERMINUS POSITION AND INTERSECTIONS\n",
    "final_images_df['tpos50'] = terminus_positions; final_images_df['tpos25'] = tpositions_25; final_images_df['tpos75'] = tpositions_75\n",
    "final_images_df['X50'] = intersections ;final_images_df['X25'] = X25; final_images_df['X75'] = X75\n",
    "print(final_images_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate terminus change rates (m/d):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into 3 dataframes\n",
    "final_images_50 = final_images_df[['Scene', 'BoxID', 'Scale', 'datetimes', 'Metric', 'Order', \n",
    "                                  'tpos50', 'X50',]].copy().reset_index(drop=True)\n",
    "final_images_50 = final_images_50.rename(columns={\"tpos50\": \"tpos\", \"X50\": \"X\"})\n",
    "final_images_25 = final_images_df[['Scene', 'BoxID', 'Scale', 'datetimes', 'Metric', 'Order', \n",
    "                                  'tpos25', 'X25']].copy().reset_index(drop=True)\n",
    "final_images_25 = final_images_25.rename(columns={\"tpos25\": \"tpos\", \"X25\": \"X\"})\n",
    "final_images_75 = final_images_df[['Scene', 'BoxID', 'Scale', 'datetimes', 'Metric', 'Order', \n",
    "                                  'tpos75', 'X75']].copy().reset_index(drop=True)\n",
    "final_images_75 = final_images_75.rename(columns={\"tpos75\": \"tpos\", \"X75\": \"X\"})\n",
    "\n",
    "dfs = [final_images_50, final_images_25, final_images_75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jukes/automated-glacier-terminus/automated_terminus_functions.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['changerate'] = tchange\n"
     ]
    }
   ],
   "source": [
    "dfs_new = []\n",
    "for df in dfs: \n",
    "    to_datetimes(df)\n",
    "    dfs_new.append(calc_changerates1(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_images_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Show each image & all (up to 5) terminus picks at a time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for index, row in dated_images_df.iterrows():\n",
    "uniquescenes = set(list(final_images_df['Scene'])); len(uniquescenes)\n",
    "\n",
    "for scene in uniquescenes:    \n",
    "    #separate the df by scene:\n",
    "    scene_df = final_images_df[final_images_df['Scene'] == scene].copy()\n",
    "\n",
    "    #sort by descending order so the worse orders are plotted first and the better orders are plotted on top\n",
    "    scene_df = scene_df.sort_values(by='Order', ascending=False);\n",
    "    \n",
    "    #grab the date for the scene (just use the first since all should be the same)\n",
    "    date = list(scene_df.datetimes)[0]\n",
    "    \n",
    "    #loop through the rows for each scene and append info to these lists\n",
    "    trimdatfiles = []; datfiles = []; orders = []; intersections50 = {}; is25 = {}; is75 = {};\n",
    "    \n",
    "    for index, row in scene_df.iterrows():\n",
    "        #grab the terminus_trim files and append to list\n",
    "        trimdatfiles.append(row['Trimmed_dat_filename']); datfiles.append(row['Dat_filename'])\n",
    "        #grab the order to be plotted later:\n",
    "        orders.append(row['Order'])\n",
    "        #grab the intersections to be plotted later:\n",
    "        intersections50.update({row['Dat_filename']: row['X50']})\n",
    "        is25.update({row['Dat_filename']: row['X25']}); is75.update({row['Dat_filename']: row['X75']})\n",
    "\n",
    "    #Read in the image.png as np array\n",
    "    image = mpimg.imread(imagepath+\"R_\"+scene+\"_B8_Buffer\"+BOI+'_PS.png')\n",
    "    \n",
    "    #Read in terminus box raster as an np array\n",
    "#     tbox = mpimg.imread(csvpaths+\"Box\"+BOI+\"/rotated_images/final/crop_Box\"+BOI+\"_raster_cut.pgm\")\n",
    "    tbox = mpimg.imread(basepath+\"Box\"+BOI+\"/rotated_c1/R_Box\"+BOI+\"_raster_cut.png\")\n",
    "    \n",
    "    #set path to that image's datfiles:\n",
    "    datpath = imagepath+\"R_\"+scene+\"_B8_Buffer\"+BOI+\"_PS.pgm_max_gaussian/\"+metric\n",
    "    \n",
    "    #grab dat xs and ys\n",
    "    datxs = {}; datys = {}\n",
    "    \n",
    "    for i in range(0, len(trimdatfiles)):\n",
    "#         trimdat = trimdatfiles[i]\n",
    "        dat = datfiles[i]\n",
    "#         print(trimdat)\n",
    "        #Read in dat file as np array and grab x and y values\n",
    "#         term_trim_dat = np.loadtxt(datpath+trimdat)\n",
    "        term_dat = np.loadtxt(datpath+dat)\n",
    "#         print(term_trim_dat.shape)\n",
    "        \n",
    "        xs = []; ys = []\n",
    "        #grab x and y coordinates for the terminus line\n",
    "        for j in term_dat:\n",
    "            x, y = (j[0], j[1]); xs.append(x); ys.append(y)\n",
    "        \n",
    "        #update into dat xs and ys dictionaries:\n",
    "        datxs.update({dat: xs}); datys.update({dat: ys})\n",
    "        \n",
    "    #grab the top pick\n",
    "    toppick = datfiles[0]\n",
    "    \n",
    "    #PLOT THE LANDSAT IMAGE and TERMINUS BOX\n",
    "    plt.figure(figsize=(20,10)); plt.axis(\"off\")\n",
    "    imgplt_trim = plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    boxplt = plt.imshow(tbox, alpha=0.1)\n",
    "    \n",
    "    #PLOT CENTERLINES\n",
    "    #grab x values from centerline_df\n",
    "#     xmin50 = float(centerline_df.loc[BOI]['lmid50_x']); xmin25 = float(centerline_df.loc[BOI]['lmid25_x'])\n",
    "#     xmax50 = float(centerline_df.loc[BOI]['rmid50_x']); xmax25 = float(centerline_df.loc[BOI]['rmid25_x'])\n",
    "#     xmin75 = float(centerline_df.loc[BOI]['lmid75_x'])\n",
    "#     xmax75 = float(centerline_df.loc[BOI]['rmid75_x'])\n",
    "#     cx50 = np.linspace(xmin50, xmax50, int(xmax50-xmin50)*2); cx75 = np.linspace(xmin75, xmax75, int(xmax75-xmin75)*2)\n",
    "#     cx25 = np.linspace(xmin25, xmax25, int(xmax50-xmin50)*2)\n",
    "#     #generate y-values using the slope and intercept\n",
    "#     cy50 = float(centerline_df.loc[BOI]['m50'])*cx50 + float(centerline_df.loc[BOI]['b50'])  \n",
    "#     cy25 = float(centerline_df.loc[BOI]['m25'])*cx25 + float(centerline_df.loc[BOI]['b25']) \n",
    "#     cy75 = float(centerline_df.loc[BOI]['m75'])*cx75 + float(centerline_df.loc[BOI]['b75']) \n",
    "#     plt.plot(cx50, cy50, '--w',cx25, cy25, '--w', cx75, cy75, '--w' ,linewidth=1.5, alpha=0.5)\n",
    "\n",
    "    #PLOT DATE in the top left corner\n",
    "    plt.text(int(0.02*image.shape[0]), int(0.035*image.shape[1]), str(date), fontsize=16, color='w')\n",
    "    \n",
    "    \n",
    "    #PLOT ALL TOP PICKS in different shades of purple\n",
    "    #create five shades for each order\n",
    "    colors = pl.cm.plasma_r(np.linspace(0,1,5))\n",
    "    col_count = 0\n",
    "    #plot number of lines\n",
    "    plt.text(int(0.02*image.shape[0]), int(0.07*image.shape[0]), \"Lines: \"+str(len(datfiles)), fontsize=16, color='w')\n",
    "    #plot each termline\n",
    "    for line in datfiles:\n",
    "        #grab the x and y values for that termline\n",
    "        x, y = datxs[line], datys[line]\n",
    "        #plot with color scheme\n",
    "        plt.plot(x, y, color=colors[col_count], linewidth=2)\n",
    "        col_count = col_count+1\n",
    "        \n",
    "    #     #PLOT TOP PICK\n",
    "#     plt.plot(datxs[toppick], datys[toppick], color='r')\n",
    "    \n",
    "#     #PLOT intersection points\n",
    "#     ix50, iy50 = intersections50.get(toppick); ix25, iy25 = is25.get(toppick); ix75, iy75 = is75.get(toppick)\n",
    "#     plt.plot(ix50, iy50, 'yx', ix25, iy25, 'yx', ix75, iy75, 'yx', markersize=6)\n",
    "#     for i_point in intersections:\n",
    "#         plt.plot(i_point[0], i_point[1], 'kx', markersize='6')\n",
    "        \n",
    "#     #PLOT midpoints for figure\n",
    "#     plt.plot(xmin50, float(centerline_df.loc[BOI]['lmid50_y']), 'ws', markersize='4')\n",
    "#     plt.plot(xmin25, float(centerline_df.loc[BOI]['lmid25_y']), 'ws', markersize='4')\n",
    "#     plt.plot(xmin75, float(centerline_df.loc[BOI]['lmid75_y']), 'ws', markersize='4')\n",
    "      \n",
    "    #SAVE AND DELAY\n",
    "    plt.savefig(basepath+\"Box\"+BOI+\"/Results_c1/\"+str(date)+\"_trim_\"+scene+\".png\", dpi=200, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    sleep(1)\n",
    "    clear_output()\n",
    "# print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['terminus_000.dat']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Plot terminus position and change rate timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering using max flow speeds\n",
    "\n",
    "Grab max flow threshold from glacier velocities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Grab max flow threshold from glacier velocities in flowspeed_df\n",
    "# max_flow = float(flowspeed_df['Max_speed'][BOI])\n",
    "# if max_flow < 1.0:\n",
    "#     flow_thresh = 5.0\n",
    "# else:\n",
    "#     flow_thresh = 5.0*max_flow\n",
    "# print(flow_thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for sudden dips in the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# #REMOVE DIPS \n",
    "# N1 = 3\n",
    "# nodips = []\n",
    "# for df in dfs_new:\n",
    "#     nodips.append(remove_dips(df, flow_thresh, N1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter for sudden jumps in the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #REMOVE JUMPS\n",
    "# N2 = 2\n",
    "# nojumps = []\n",
    "# for df in nodips:\n",
    "#     nojumps.append(remove_jumps(df, flow_thresh, N2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "# # ax1.plot(final_images_df['datetimes'], final_images_df['term_position'], 'mo', markersize = 5)\n",
    "# colors = pl.cm.plasma(np.linspace(0,1,5))\n",
    "\n",
    "# df1 = final_images_50[final_images_50['Order'] == '1'].copy(); df2 = final_images_50[final_images_50['Order'] == '2'].copy()\n",
    "# df3 = final_images_50[final_images_50['Order'] == '3'].copy(); df4 = final_images_50[final_images_50['Order'] == '4'].copy()\n",
    "# df5 = final_images_50[final_images_50['Order'] == '5'].copy()\n",
    "\n",
    "# ax1.plot(df5['datetimes'], df5['tpos'], color = colors[4], marker='o', markersize=5, lw=0)\n",
    "# ax1.plot(df4['datetimes'], df4['tpos'], color = colors[3], marker='o', markersize=5, lw=0)\n",
    "# ax1.plot(df3['datetimes'], df3['tpos'], color = colors[2], marker='o', markersize=5, lw=0)\n",
    "# ax1.plot(df2['datetimes'], df2['tpos'], color = colors[1], marker='o', markersize=5, lw=0)\n",
    "# ax1.plot(df1['datetimes'], df1['tpos'], color = colors[0], marker='o', markersize=5, lw=0)\n",
    "\n",
    "# ax1.set_ylabel('Terminus position (m)', color='k', fontsize=14)\n",
    "# ax1.set_xlabel('Date', fontsize=14)\n",
    "# ax1.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# # plt.savefig(csvpaths+\"/Figures/filtering/Timeseries_final_top1_\"+BOI+\"_\"+analysis_date+\".png\", dpi=500)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_time = list(final_images_df['datetimes'])[0]\n",
    "# max_time = list(final_images_df['datetimes'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "# #TERMINUS POSITION\n",
    "# ax1.plot(nojumps75['datetimes'], nojumps75['tpos'], 'mo', markersize='4')\n",
    "# # ax1.plot(dips_df['datetimes'], dips_df['Term_position'], 'ko', markersize='4')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grab only those terminus positions corresponding to the highest order terminus pick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# orders25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #Grab highest orders:\n",
    "# highestorder_dfs = []\n",
    "# for df in nojumps:\n",
    "#     #grab unique dates\n",
    "#     unique_dates = set(list(df['datetimes']))\n",
    "#     print(len(unique_dates))\n",
    "#     #grab highest orders:\n",
    "#     order_list = []\n",
    "#     for date in unique_dates:\n",
    "#         date_df = df[df['datetimes'] == date].copy()\n",
    "#         highestorder = np.min(np.array(date_df['Order']))\n",
    "#         order_list.append(highestorder)\n",
    "#     highestorder_df = pd.DataFrame(list(zip(unique_dates, order_list)), columns=['datetimes', 'Order']).sort_values(by='datetimes', ascending=True)\n",
    "#     highestorder_dfs.append(highestorder_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inner merge with final_images_df to only keep those of the highest order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# onepick_dfs = []\n",
    "# for i in range(0, len(highestorder_dfs)):\n",
    "#     onepick_df = nojumps[i].merge(highestorder_dfs[i], how='inner', on=['datetimes', 'Order'])\n",
    "#     onepick_dfs.append(onepick_df)\n",
    "#     print(onepick_df.shape[0])\n",
    "    \n",
    "# onepick_df = nojumps.merge(highestorder_df, how='inner', on=['datetimes', 'Order']); print(onepick_df.shape[0])\n",
    "# onepick_df25 = nojumps25.merge(highestorder_df25, how='inner', on=['datetimes', 'Order']); print(onepick_df25.shape[0])\n",
    "# onepick_df75 = nojumps75.merge(highestorder_df75, how='inner', on=['datetimes', 'Order']); print(onepick_df75.shape[0])\n",
    "# onepick_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onepick_df = final_images_df.merge(highestorder_df, how='inner', on=['datetimes', 'Order'])\n",
    "# print(onepick_df.shape[0])\n",
    "# onepick_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# posmax = np.max(onepick_df['tpos']); print(posmax)\n",
    "# posmax25 = np.max(onepick_df25['tpos']); print(posmax25)\n",
    "# posmax75 = np.max(onepick_df75['tpos']); print(posmax75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig, ax1 = plt.subplots(figsize=(12,4))\n",
    "# markers = ['mo', 'ro', 'bo']\n",
    "\n",
    "# #PLOT TERMINUS POSITIONS ALONG 3 CENTERLINES\n",
    "# for j in range(0, len(onepick_dfs)):\n",
    "#     df = onepick_dfs[j];    print(len(df))\n",
    "#     ax1.plot(df['datetimes'], df['tpos'], markers[j], markersize=5, alpha=0.8)\n",
    "\n",
    "# # final_images_df.plot(x='datetimes', y='term_position', \n",
    "# #             c=final_images_df['Order'], markersize='4', colormap='RdPu_r', legend=None)\n",
    "# ax1.set_ylabel('Terminus position (m)', color='k', fontsize=12)\n",
    "\n",
    "# #GENERAL PLOT PARAMETERS\n",
    "# ax1.set_title(\"Box\"+BOI, fontsize=16)\n",
    "# ax1.set_xlabel('Date', fontsize=12)\n",
    "# ax1.tick_params(axis='both', which='major', labelsize=12)\n",
    "\n",
    "# #SAVE FIGURE\n",
    "# plt.savefig(csvpaths+\"/Figures/Termposition_LS8_m_Box\"+BOI+\"_\"+analysis_date+\".png\", dpi=200)\n",
    "# plt.legend(['1/2', '1/4', '3/4'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flowlines = ['flowline50', 'flowline25', 'flowline75']\n",
    "# for k in range(0, len(onepick_dfs)):\n",
    "#     df = onepick_dfs[k];\n",
    "#     df.to_csv(path_or_buf = csvpaths+'Tpos_Box'+BOI+'_'+flowlines[k]+'_filtered.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
